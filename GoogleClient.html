<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio to Text with Google Speech-to-Text</title>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/recorderjs/0.1.0/recorder.js" integrity="sha512-zSq4Vvm00k8M01OLF/SmwKryVpA7YVXIbEFHU1rvNw3pgH50SjL6O4nDbB65V76YKWmr3rPABOXJ+uz+Z3BEmw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <h1>Real-time Audio to Text with Google Speech-to-Text</h1>
    <button id="startButton">Start Recording</button>
    <p id="output"></p>    
    <script>
        const startButton = document.getElementById('startButton');
        const outputElement = document.getElementById('output');
        let recorder;
        let audioContext;

        const recorderWorkletCode = `
            class RecorderWorkletProcessor extends AudioWorkletProcessor {
                constructor() {
                    super();
                    this.recordedChunks = [];
                }

                process(inputs, outputs) {
                    const input = inputs[0];
                    this.recordedChunks.push(input[0].slice());
                    return true;
                }

                static get parameterDescriptors() {
                    return [];
                }
            }

            registerProcessor('recorder-worklet', RecorderWorkletProcessor);
        `;

        startButton.addEventListener('click', async () => {
            startButton.disabled = true;
            outputElement.textContent = '';

            try {
                audioContext = new AudioContext();
                const blob = new Blob([recorderWorkletCode], { type: 'application/javascript' });
                const dataUrl = URL.createObjectURL(blob);

                await audioContext.audioWorklet.addModule(dataUrl);
                const recorderNode = new AudioWorkletNode(audioContext, 'recorder-worklet');
                audioContext.resume();

                recorder = new MediaRecorder(audioContext.createMediaStreamDestination());
                recorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        const audioContent = btoa(String.fromCharCode.apply(null, new Uint8Array(event.data)));
                        sendAudioData(audioContent);
                    }
                };

                recorderNode.port.onmessage = (event) => {
                    if (event.data === 'stop') {
                        recorder.stop();
                        startButton.disabled = false;
                    }
                };

                recorderNode.connect(audioContext.destination);
                recorder.start();
            } catch (error) {
                console.error('Error accessing microphone:', error);
                startButton.disabled = false;
            }
        });

        document.addEventListener('keydown', (event) => {
            if (event.key === 'Enter') {
                stopRecording();
            }
        });

        document.addEventListener('keyup', (event) => {
            if (event.key === 'Enter') {
                startRecording();
            }
        });

        function stopRecording() {
            recorder.stop();
        }

        function startRecording() {
            startButton.disabled = false;
            recorder = new MediaRecorder(audioContext.createMediaStreamDestination());
            recorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    const audioContent = btoa(String.fromCharCode.apply(null, new Uint8Array(event.data)));
                    sendAudioData(audioContent);
                }
            };
            recorder.start();
        }

        function sendAudioData(audioContent) {
            fetch('http://localhost:3000/streamingRecognize', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ audioContent }),
            })
            .then(response => response.json())
            .then(data => {
                console.log('Server Response:', data);

                if (data.transcription) {
                    outputElement.textContent = data.transcription;
                }
            })
            .catch(error => {
                console.error('Error sending audio data to server:', error);
            });
        }
    </script>
    <!-- <script>
        const startButton = document.getElementById('startButton');
        const outputElement = document.getElementById('output');
        let recorder;

        startButton.addEventListener('click', () => {
            startButton.disabled = true;
            outputElement.textContent = '';

            // Start recording
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    recorder = new Recorder(stream);
               //     recorder.record();
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                    startButton.disabled = false;
                });
        });

        document.addEventListener('keydown', (event) => {
            if (event.key === 'Enter') {
                stopRecording();
            }
        });

        document.addEventListener('keyup', (event) => {
            if (event.key === 'Enter') {
                startRecording();
            }
        });

        function stopRecording() {
            recorder.stop();
            recorder.exportWAV((blob) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const audioContent = reader.result.split(',')[1];
                    sendAudioData(audioContent);
                };
                reader.readAsDataURL(blob);
            });
        }

        function startRecording() {
            startButton.disabled = false;
            recorder.clear();
            recorder.record();
        }

        function sendAudioData(audioContent) {
            fetch('http://localhost:3000/streamingRecognize', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ audioContent }),
            })
            .then(response => response.json())
            .then(data => {
                console.log('Server Response:', data);

                if (data.transcription) {
                    outputElement.textContent = data.transcription;
                }
            })
            .catch(error => {
                console.error('Error sending audio data to server:', error);
            });

            startRecording();
        }
    </script> -->
</body>
</html>

<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio to Text with Google Speech-to-Text</title>
</head>
<body>
    <h1>Real-time Audio to Text with Google Speech-to-Text</h1>
    <button id="startButton">Start Recording</button>
    <p id="output"></p>

    <script>
        const startButton = document.getElementById('startButton');
        const outputElement = document.getElementById('output');

        // Replace with your Google Cloud Speech-to-Text API key
        const apiKey = 'AIzaSyCrV_O1vMe5kN29-g85GknRx6o6n0qABCQ';

        let recognition;

        startButton.addEventListener('click', () => {
            startButton.disabled = true;
            outputElement.textContent = '';

            // Initialize the SpeechRecognition object
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            // Start recording and send audio data to Google Speech-to-Text
            recognition.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript;
                const isFinal = event.results[event.results.length - 1].isFinal;

                if (isFinal) {
                    console.log('transcript is '+transcript)
                    const audioContent = btoa(transcript);
                    console.log(audioContent)
                    sendAudioData(audioContent);
                }
            };

            // Stop recording
            recognition.onend = () => {
                startButton.disabled = false;
            };

            // Start the speech recognition
            recognition.start();
        });

        function sendAudioData(audioContent) {
            const apiUrl = `https://speech.googleapis.com/v1/speech:recognize?key=${apiKey}`;
            
            const requestBody = {
                audio: {
                    content: audioContent,
                },
                config: {
                    encoding: 'LINEAR16',
                    sampleRateHertz: 16000,
                    languageCode: 'en-US',
                },
            };

            fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(requestBody),
            })
            .then(response => response.json()
            )
            .then(data => {
                for (const prop in data) {
                    if (Object.prototype.hasOwnProperty.call(data, prop)) {
                        console.log(`${prop}:`, data[prop]);
                    }
                }
                if (data.results && data.results.length > 0) {
                    const transcription = data.results[0].alternatives[0].transcript;
                    outputElement.textContent = transcription;
                }
            })
            .catch(error => {
                console.error('Error sending audio data:', error);
            });
        }
    </script>
</body>
</html> -->

<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio to Text with Google Speech-to-Text</title>
</head>
<body>
    <h1>Real-time Audio to Text with Google Speech-to-Text</h1>
    <button id="startButton">Start Recording</button>
    <p id="output"></p>

    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-storage.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-analytics.js"></script>
    <script>
        const startButton = document.getElementById('startButton');
        const outputElement = document.getElementById('output');
        // Initialize Firebase with your credentials
        const firebaseConfig = {
  project_id: 'transcribe-qa',
  private_key_id: '0e1820b147ab3eecd9b6750a3f39594d9294a814',
  private_key: 'MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCmtZcEOMNJnGWT\nwbjoccykfv2+kguwRBQgwj/ZBp/h2iF/5oPYt89M8ZL1t80kixBySLUdaOYht544\n3Cj2kAvj4V8xnIuRVqonuWxN2RcPHh+bgU+lwxEgHgnSnjBb2t6I5W4PzyK0Lx06\nDW4D3ruY4QILTZPlW6asP1t4Z128eqiEY8Y6dkH2SP7mQ6qJfZ0bETocUPVEe1ZR\nKZTRn64M1gt1/Oo5PSJ8BUO0LmATvI5NlICTXFn6gnUblfm0vEqfJjnJHv9IReuA\nh96lZHrQdJfq5tok4fWuVwEa6kekkso+SFpAPcp/GnCj3fwxceDmHHmgZtYbLx0q\nXKhayzYPAgMBAAECggEAAU00h/+/Nzlap27qK09jqpmZn6bMk8NqEZ3OzLAZ1TlE\n2GiOQOSC+iZ+dK6Xz5iW/6R3cQ6Kh6yzz90ya7fWHV57LER308XeP4JuTgq73epZ\nfm0Ag8sfN211QGpH7Ma1zwqIVPkvwkH76WSZxQ1TVctaBTbPw6znrBKHCwTQYmGb\nE11HLx7cR7/yvbgwHQv5qtpKPBhdcwo+6292n3dmMOQIe1H+OywYxmbOXPP4YNFP\n+OeQaDbNPM1ASx8EzvUrCaI/D2Fd0bxE0/bcdqDOpR5lkqgWhXv7xAdrAp27frf5\nDmeFrcbojbhcVLwvv16CsT9yCRAH0ZqMUFKpqAmqAQKBgQDR80DQVcoIurpzEhzI\nYZXfCiPDnqL4c55EQAO2c1ZTOIf4SxFlFF00OOacwRu2WuHz4Itn4IhtkCI5Cs5D\nKJsJ5GYAQa+JqjbTTEFgTiP21jfSjE3ZC94ykbpRcJJnapAX1XRSJHvyvrqH76Fp\nxDET26PAWk4WTyxgIMtX6JjIoQKBgQDLRlpcZeQoeh8msRDAzDQc85IP380TIJX3\nXqUUN5JAbYdYLJBJkGsBBlTInGl93FnOykke5LHQ/yUCkD5h5//BFrn0MT+MuI0r\n8KDla6tiwPXw3royLqfhNFCjmc02sfOZmvhprgj2QZkowZYRDE2yvsudKYad/6jX\n8E2469AQrwKBgQCgOZNqKz6PYOnv7Y+3wPmeiN94Z/WZxKqxDWWH9QeZZVgnPird\nSChFNXORh7I9fahY9TGOqgWUD95+R+fXywJfD0ZkxbxQRG2o3dY6yAecVimt7lNu\n5CbD0wEtK8sfT2z+M3GdSqipPbOfEFrQG+EUdZfHsWNMlUmZZw2oXiNTYQKBgQCF\n788uPny9JupLpjOxtVtJEDxXdVE8nyXxHk2LKqqVBRY+xO41apD21eMbY+QmaABM\nvwC6+FkpqlQKglx4SlM8OOtBuQl0gU2TfDOntu/wW9Axa7AnzJIVU1Em2vpaZZpq\nxa+UgnWpPMPcFOH6Ta8Mbabf4TKv/HqV/eJYTBiGRQKBgFtWP40CiKzxj2Cb8c7v\nNXqKHkodp57tn8b7FAY36XYZPzTnbZRZhIxkuqhN696Ci3AZJECqy+d8zGni41Li\nuqGvbq4sniZcAtD50qBClY6ULj8RUPP7XKBc57E+t+LI4NFzD/UGW8OG1QrcKSms\nFfc4vqscFOZQNxjCVeoKPBj5',
  client_email: 'transcribe-qa@transcribe-qa.iam.gserviceaccount.com',
  client_id: '113161217613682193707',
  auth_uri: 'https://accounts.google.com/o/oauth2/auth',
  token_uri: 'https://oauth2.googleapis.com/token',
  auth_provider_x509_cert_url: 'https://www.googleapis.com/oauth2/v1/certs',
  client_x509_cert_url: 'https://www.googleapis.com/robot/v1/metadata/x509/transcribe-qa%40transcribe-qa.iam.gserviceaccount.com',
  universe_domain: 'googleapis.com'

            // apiKey: 'AIzaSyCrV_O1vMe5kN29-g85GknRx6o6n0qABCQ',
            // authDomain: 'YOUR_AUTH_DOMAIN',
            // projectId: 'YOUR_PROJECT_ID',
            // storageBucket: 'YOUR_STORAGE_BUCKET',
            // messagingSenderId: 'YOUR_MESSAGING_SENDER_ID',
            // appId: 'YOUR_APP_ID',
            // measurementId: 'YOUR_MEASUREMENT_ID'
        };

        firebase.initializeApp(firebaseConfig);

        const db = firebase.firestore();

        // Replace with your Google Cloud Speech-to-Text API key
        const apiKey = 'AIzaSyCrV_O1vMe5kN29-g85GknRx6o6n0qABCQ';

        let recognition;

        startButton.addEventListener('click', () => {
            startButton.disabled = true;
            outputElement.textContent = '';

            // Initialize the SpeechRecognition object
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            // Set up the streaming connection to Google Speech-to-Text
            const socket = new WebSocket(`wss://speech.googleapis.com/v1/speech:streaming?access_token=${apiKey}`);            
            // Handle the WebSocket connection events
            socket.onopen = () => {
                console.log('WebSocket connection opened');
            };

            socket.onmessage = (event) => {
                const data = JSON.parse(event.data);

                if (data && data.results && data.results.length > 0) {
                    const transcription = data.results[0].alternatives[0].transcript;
                    outputElement.textContent = transcription;
                }
            };

            socket.onerror = (error) => {
                console.error('WebSocket error:', error);
            };

            socket.onclose = () => {
                console.log('WebSocket connection closed');
                startButton.disabled = false;
            };

            // Start recording and send audio data to Google Speech-to-Text
            recognition.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript;
                const isFinal = event.results[event.results.length - 1].isFinal;

                if (isFinal) {
                    const message = {
                        streamingConfig: {
                            config: {
                                encoding: 'LINEAR16',
                                sampleRateHertz: 16000,
                                languageCode: 'en-US',
                            },
                        },
                        audioContent: btoa(transcript),
                    };

                    socket.send(JSON.stringify(message));
                }
            };

            // Stop recording and close the WebSocket connection
            recognition.onend = () => {
                socket.close();
            };

            // Start the speech recognition
            recognition.start();
        });
    </script>
</body>
</html> -->
